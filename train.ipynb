{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e44fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (4.55.2)\n",
      "Requirement already satisfied: tokenizers in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (0.21.4)\n",
      "Requirement already satisfied: sentencepiece in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: tiktoken in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: filelock in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (from transformers) (0.34.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/idok/random/julia/MLproj/.venv/lib/python3.10/site-packages (from requests->transformers) (2025.7.14)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers tokenizers sentencepiece tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3129497-4160-4af9-ad70-7fc1c40da907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import optuna\n",
    "import wandb\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.functional import softmax as torch_softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# PRETRAIN_MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "PRETRAIN_MODEL = \"microsoft/deberta-v3-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49229453-51c0-4692-b178-32346d02a29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cd4c40-f8b0-44b0-948a-dbeac84df1d0",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb92993-538b-484d-a161-eff6974a663d",
   "metadata": {},
   "source": [
    "The dataset used in this project is sourced from [Kaggle - Coronavirus tweets NLP](https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa61b86-fb34-4516-93e9-a87e9c00d124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44953</td>\n",
       "      <td>NYC</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44954</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>44955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>Find out how you can protect yourself and love...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44956</td>\n",
       "      <td>Chicagoland</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>44957</td>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>03/03/2020</td>\n",
       "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ï»¿UserName  ScreenName             Location     TweetAt  \\\n",
       "0            1       44953                  NYC  02/03/2020   \n",
       "1            2       44954          Seattle, WA  02/03/2020   \n",
       "2            3       44955                  NaN  02/03/2020   \n",
       "3            4       44956          Chicagoland  02/03/2020   \n",
       "4            5       44957  Melbourne, Victoria  03/03/2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n",
       "1  When I couldn't find hand sanitizer at Fred Me...            Positive  \n",
       "2  Find out how you can protect yourself and love...  Extremely Positive  \n",
       "3  #Panic buying hits #NewYork City as anxious sh...            Negative  \n",
       "4  #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df_train = pd.read_csv(\"data/Corona_NLP_train.csv\", encoding='latin1')\n",
    "df_test = pd.read_csv(\"data/Corona_NLP_test.csv\", encoding='latin1')\n",
    "\n",
    "# Display first few rows\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9db0d07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44953</td>\n",
       "      <td>NYC</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44954</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>44955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>Find out how you can protect yourself and love...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44956</td>\n",
       "      <td>Chicagoland</td>\n",
       "      <td>02/03/2020</td>\n",
       "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>44957</td>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>03/03/2020</td>\n",
       "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ï»¿UserName  ScreenName             Location     TweetAt  \\\n",
       "0            1       44953                  NYC  02/03/2020   \n",
       "1            2       44954          Seattle, WA  02/03/2020   \n",
       "2            3       44955                  NaN  02/03/2020   \n",
       "3            4       44956          Chicagoland  02/03/2020   \n",
       "4            5       44957  Melbourne, Victoria  03/03/2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \\\n",
       "0  TRENDING: New Yorkers encounter empty supermar...  Extremely Negative   \n",
       "1  When I couldn't find hand sanitizer at Fred Me...            Positive   \n",
       "2  Find out how you can protect yourself and love...  Extremely Positive   \n",
       "3  #Panic buying hits #NewYork City as anxious sh...            Negative   \n",
       "4  #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral   \n",
       "\n",
       "   Label  \n",
       "0      0  \n",
       "1      3  \n",
       "2      4  \n",
       "3      1  \n",
       "4      2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map sentiment to integers\n",
    "sentiment_map = {\n",
    "    'Extremely Negative': 0,\n",
    "    'Negative': 1,\n",
    "    'Neutral': 2,\n",
    "    'Positive': 3,\n",
    "    'Extremely Positive': 4\n",
    "}\n",
    "\n",
    "df_train['Label'] = df_train['Sentiment'].map(sentiment_map)\n",
    "df_test['Label'] = df_test['Sentiment'].map(sentiment_map)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff8c827-91cf-4d35-8fb6-f4d2786853bf",
   "metadata": {},
   "source": [
    "#### Split the training data into train and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47867911-48e8-49ee-b67a-85ddb93b0ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, eval_df = train_test_split(\n",
    "    df_train,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=df_train['Label']\n",
    ")\n",
    "\n",
    "train_df = train_df[['OriginalTweet', 'Label']].reset_index(drop=True)\n",
    "eval_df = eval_df[['OriginalTweet', 'Label']].reset_index(drop=True)\n",
    "test_df = df_test[['OriginalTweet', 'Label']].reset_index(drop=True)\n",
    "\n",
    "train_df.to_csv('data/train_data.csv', index=False)\n",
    "eval_df.to_csv('data/eval_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be809608-1ac1-47ed-8eec-2ea2139104b4",
   "metadata": {},
   "source": [
    "### Look at the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0a40fa7-8ece-4b5d-b317-b32e4c3a54d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(PRETRAIN_MODEL, num_labels=5, ignore_mismatched_sizes=True).to(device)\n",
    "#model # Lets just look at the structure of the reoerta model from HF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4c5bea-d5b1-41e1-8b35-797b03f0507e",
   "metadata": {},
   "source": [
    "### Check how the data is tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1e74f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    41157.000000\n",
      "mean        55.744078\n",
      "std         21.730697\n",
      "min          3.000000\n",
      "25%         40.000000\n",
      "50%         55.000000\n",
      "75%         70.000000\n",
      "max        249.000000\n",
      "Name: OriginalTweet, dtype: float64 {0.9: 84.0, 0.95: 92.0, 0.99: 107.0}\n"
     ]
    }
   ],
   "source": [
    "# check num of tokens to choose truncation max_length\n",
    "#tok = AutoTokenizer.from_pretrained(PRETRAIN_MODEL, use_fast=True)\n",
    "#lens = df_train['OriginalTweet'].astype(str).map(lambda t: len(tok.encode(t, add_special_tokens=True)))\n",
    "#lens.describe(), lens.quantile([0.90, 0.95, 0.99]).to_dict()\n",
    "\n",
    "from transformers import DebertaV2Tokenizer\n",
    "tok = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-base\", use_fast=True)\n",
    "lens = df_train['OriginalTweet'].astype(str).map(\n",
    "    lambda t: len(tok.encode(t, add_special_tokens=True))\n",
    ")\n",
    "print(lens.describe(), lens.quantile([0.90, 0.95, 0.99]).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d221302",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b093444-596b-4b0f-80ac-99c1441e8349",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.texts = dataframe['OriginalTweet'].tolist()\n",
    "        self.labels = dataframe['Label'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c55f7255-ae13-4e50-9344-7d0ef8628cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stop_check(patience, best_f1, best_f1_epoch, current_f1, current_f1_epoch):\n",
    "    early_stop_flag = False\n",
    "    if current_f1 > best_f1:\n",
    "        best_f1 = current_f1\n",
    "        best_f1_epoch = current_f1_epoch\n",
    "    else:\n",
    "        if current_f1_epoch - best_f1_epoch > patience:\n",
    "            early_stop_flag = True\n",
    "    return best_f1, best_f1_epoch, early_stop_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a3284d8-be32-4b33-b6a8-0d214c31ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_hyperparams(model, train_loader, val_loader, optimizer, criterion, epochs, patience, trial, scheduler):\n",
    "    best_val_f1 = 0.0\n",
    "    best_f1_epoch = 0\n",
    "    early_stop_flag = False\n",
    "    best_model_state = None\n",
    "\n",
    "    # Enable automatic mixed precision on CUDA for stability/speed\n",
    "    scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train() # Enable training mode\n",
    "        train_loss = 0.0\n",
    "        total_train_samples = 0\n",
    "        correct_train_predictions = 0\n",
    "\n",
    "        for batch in train_loader: #Iterates over the train_loader, which is a DataLoader object containing batches of training data.\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True) # Reset gradients\n",
    "\n",
    "            # Forward pass (with AMP); save the logits (the raw output of the model) and calculate loss\n",
    "            with torch.amp.autocast(\"cuda\", enabled=(device.type == \"cuda\")):\n",
    "                outputs = model(input_ids, attention_mask=attention_mask) # Forward pass\n",
    "                logits = outputs.logits\n",
    "                loss = criterion(logits, labels) # Calculate loss\n",
    "\n",
    "            # Backward pass (with AMP) + gradient clipping, then update weights using the optimizer\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # NEW: prevent exploding gradients\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # NEW: step the LR scheduler once per optimizer step\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            # Accumulate training loss and predictions\n",
    "            train_loss += loss.item() * input_ids.size(0)\n",
    "            total_train_samples += input_ids.size(0)\n",
    "            correct_train_predictions += (logits.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        train_loss /= total_train_samples\n",
    "        train_accuracy = correct_train_predictions / total_train_samples\n",
    "\n",
    "        ###  Validation loop  ###\n",
    "        model.eval() # Enable evaluation mode\n",
    "        val_loss = 0.0\n",
    "        total_val_samples = 0\n",
    "        correct_val_predictions = 0\n",
    "\n",
    "        all_val_labels = []\n",
    "        all_val_preds = []\n",
    "        all_val_probs = []\n",
    "\n",
    "        with torch.no_grad(): # Disable gradient computation\n",
    "            for batch in val_loader: # iterate on the val_loader's batches \n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "                val_loss += loss.item() * input_ids.size(0)\n",
    "                total_val_samples += input_ids.size(0)\n",
    "                correct_val_predictions += (logits.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "                all_val_preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
    "                all_val_probs.append(torch_softmax(logits, dim=1).cpu().numpy())\n",
    "\n",
    "        # calculate metrics \n",
    "        val_loss /= total_val_samples\n",
    "        val_accuracy = correct_val_predictions / total_val_samples\n",
    "        val_precision = precision_score(all_val_labels, all_val_preds, average='macro')\n",
    "        val_recall = recall_score(all_val_labels, all_val_preds, average='macro')\n",
    "        val_f1 = f1_score(all_val_labels, all_val_preds, average='macro')\n",
    "\n",
    "        probs = np.concatenate(all_val_probs, axis=0)\n",
    "        labels_np = np.asarray(all_val_labels)\n",
    "        try:\n",
    "            val_auc = roc_auc_score(labels_np, probs, multi_class='ovr', average='macro')\n",
    "        except ValueError:\n",
    "            # \n",
    "            val_auc = float('nan')\n",
    "\n",
    "        # Check for early stopping (UNCHANGED: still based on accuracy)\n",
    "        best_val_f1, best_f1_epoch, early_stop_flag = early_stop_check(\n",
    "            patience, best_val_f1, best_f1_epoch, val_f1, epoch\n",
    "        )\n",
    "\n",
    "        # Save the best model under the best_model_state parameter by f1\n",
    "        if val_f1 >= best_val_f1:\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        print(f\"Epoch {epoch}: train_loss={train_loss:.4f} val_f1={val_f1:.4f}, best_val_f1={best_val_f1:.4f}\")\n",
    "\n",
    "        # Log metrics to Weights & Biases - THIS IS WHERE WE TRACK THE RESULTS AND THE PROCESS\n",
    "        wandb.log({ #log == logging of the training process (e.g. results) - will be done each epoch\n",
    "            \"Epoch\": epoch,\n",
    "            \"Train Loss\": train_loss,\n",
    "            \"Train Accuracy\": train_accuracy,\n",
    "            \"Validation Loss\": val_loss,\n",
    "            \"Validation Accuracy\": val_accuracy,\n",
    "            \"Validation Precision\": val_precision,\n",
    "            \"Validation Recall\": val_recall,\n",
    "            \"Validation F1\": val_f1,\n",
    "            \"Validation AUC\": val_auc,\n",
    "\n",
    "        })\n",
    "\n",
    "        if early_stop_flag:  # Checks whether the early stopping condition has been met, as indicated by the early_stop_flag\n",
    "            break # Exits the training loop immediately if the early stopping condition is satisfied\n",
    "\n",
    "    if best_model_state is not None: # Save the best model as a .pt file\n",
    "        torch.save(best_model_state, f\"best_model_trial_{trial.number}.pt\")\n",
    "\n",
    "    return best_val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3214c37-4ebf-48bc-8c94-8dcc30199bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import DebertaV2Tokenizer\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-base\", use_fast=True)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(PRETRAIN_MODEL, use_fast=True)\n",
    "\n",
    "# Objective Function for Optuna\n",
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 5e-3, 3e-2)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])  # use grad accumulation if VRAM is tight\n",
    "    num_layers = trial.suggest_categorical(\"num_layers\", [2, 3, 4, 5])\n",
    "    patience = 5\n",
    "\n",
    "    train_dataset = TweetDataset(train_df, tokenizer) # Create the TweetDataset object\n",
    "    val_dataset = TweetDataset(eval_df, tokenizer)    # Create the TweetDataset object\n",
    "\n",
    "    data_collator = DataCollatorWithPadding(tokenizer, padding=True, return_tensors=\"pt\", pad_to_multiple_of=8)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                num_workers=6, pin_memory=True, persistent_workers=True, collate_fn=data_collator)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=6,\n",
    "                                pin_memory=True, persistent_workers=True, collate_fn=data_collator)\n",
    "\n",
    "    #model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\", num_labels=5, ignore_mismatched_sizes=True).to(device)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(PRETRAIN_MODEL, num_labels=5, ignore_mismatched_sizes=True).to(device)\n",
    "\n",
    "    # model.base_model.<...> when changing the model to something else\n",
    "    for param in model.base_model.parameters():    # Freeze layers\n",
    "        param.requires_grad = False\n",
    "    for param in model.base_model.encoder.layer[-num_layers:].parameters():     # unfreeze the last \"num_layers\" of the encoder\n",
    "        param.requires_grad = True\n",
    "    for param in model.classifier.parameters():    #unfreeze the classifier\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    # AdamW optimizer (transformer-friendly) instead of plain Adam\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # class-weighted CrossEntropy to handle label imbalance\n",
    "    counts = train_df['Label'].value_counts().sort_index().values\n",
    "    weights = torch.tensor((counts.sum() / (counts + 1e-9)), dtype=torch.float32, device=device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "    # LR scheduler with warmup (linear decay)\n",
    "    epochs = 20  # keep your epoch budget here so we can compute total steps\n",
    "    num_training_steps = epochs * len(train_loader)\n",
    "    num_warmup_steps = int(0.06 * num_training_steps)  # ~6% warmup\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n",
    "\n",
    "    # Initialize Weights & Biases - the values in the config are the properties of each trial.\n",
    "    model_name = PRETRAIN_MODEL.split(\"/\")[1]\n",
    "    wandb.init(\n",
    "        # project=\"bertweet-covid-sentiment\",\n",
    "        project=f\"covid-sentiment-twitter-{model_name}\",\n",
    "               config={ \n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"patience\": patience,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"num_layers\": num_layers,\n",
    "        # \"architecture\": \"BERTweet\",\n",
    "        # \"architecture\": \"RoBERTa\",\n",
    "        \"architecture\": \"DeBERTa\",\n",
    "        \"dataset\": \"COVID-19 NLP\"}, \n",
    "        name=f\"trial_{trial.number}\") # The name that will be saved in the W&B platform\n",
    "\n",
    "    # Train the model and get the best validation accuracy\n",
    "    best_val_f1 = train_model_with_hyperparams(\n",
    "        model, train_loader, val_loader, optimizer, criterion,\n",
    "        epochs=epochs, patience=patience, trial=trial, scheduler=scheduler\n",
    "    )\n",
    "\n",
    "    wandb.finish() # Finish the Weights & Biases run\n",
    "    \n",
    "    return best_val_f1 # Return best validation acc as the objective to maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8d569ea-b1a9-4e2d-909b-8b6de30b1d4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-18 20:44:38,480] A new study created in memory with name: no-name-33d28cfc-8f3e-46c7-bba6-03d3d7801a49\n",
      "/tmp/ipykernel_2912973/2845401944.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
      "/tmp/ipykernel_2912973/2845401944.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 5e-3, 3e-2)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myoyulia\u001b[0m (\u001b[33myoyulia-tel-aviv-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idok/git/deep-tweet-covid/wandb/run-20250818_204440-bivaucdb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/bivaucdb' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/bivaucdb' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/bivaucdb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idok/git/deep-tweet-covid/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.6100 val_f1=0.1352, best_val_f1=0.1352\n",
      "Epoch 2: train_loss=1.3806 val_f1=0.5088, best_val_f1=0.5088\n",
      "Epoch 3: train_loss=1.0212 val_f1=0.6071, best_val_f1=0.6071\n",
      "Epoch 4: train_loss=0.9078 val_f1=0.5771, best_val_f1=0.6071\n",
      "Epoch 5: train_loss=0.8311 val_f1=0.6415, best_val_f1=0.6415\n",
      "Epoch 6: train_loss=0.7712 val_f1=0.6603, best_val_f1=0.6603\n",
      "Epoch 7: train_loss=0.7155 val_f1=0.6754, best_val_f1=0.6754\n",
      "Epoch 8: train_loss=0.6944 val_f1=0.6713, best_val_f1=0.6754\n",
      "Epoch 9: train_loss=0.6645 val_f1=0.6818, best_val_f1=0.6818\n",
      "Epoch 10: train_loss=0.6401 val_f1=0.6767, best_val_f1=0.6818\n",
      "Epoch 11: train_loss=0.6302 val_f1=0.6814, best_val_f1=0.6818\n",
      "Epoch 12: train_loss=0.5968 val_f1=0.6877, best_val_f1=0.6877\n",
      "Epoch 13: train_loss=0.5604 val_f1=0.6855, best_val_f1=0.6877\n",
      "Epoch 14: train_loss=0.5386 val_f1=0.6927, best_val_f1=0.6927\n",
      "Epoch 15: train_loss=0.5132 val_f1=0.6898, best_val_f1=0.6927\n",
      "Epoch 16: train_loss=0.4968 val_f1=0.6843, best_val_f1=0.6927\n",
      "Epoch 17: train_loss=0.4861 val_f1=0.6897, best_val_f1=0.6927\n",
      "Epoch 18: train_loss=0.4755 val_f1=0.6945, best_val_f1=0.6945\n",
      "Epoch 19: train_loss=0.4728 val_f1=0.6943, best_val_f1=0.6945\n",
      "Epoch 20: train_loss=0.4661 val_f1=0.6944, best_val_f1=0.6945\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▆▆▆▇▇▇▇▇▇████████</td></tr><tr><td>Train Loss</td><td>█▇▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Validation AUC</td><td>▁▆▇▇████████████████</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▆▇▇██████████████</td></tr><tr><td>Validation F1</td><td>▁▆▇▇▇███████████████</td></tr><tr><td>Validation Loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂</td></tr><tr><td>Validation Precision</td><td>▁▅▇▇▇▇██████████████</td></tr><tr><td>Validation Recall</td><td>▁▆▇▇▇███████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.80614</td></tr><tr><td>Train Loss</td><td>0.46606</td></tr><tr><td>Validation AUC</td><td>0.91443</td></tr><tr><td>Validation Accuracy</td><td>0.68278</td></tr><tr><td>Validation F1</td><td>0.69437</td></tr><tr><td>Validation Loss</td><td>0.87482</td></tr><tr><td>Validation Precision</td><td>0.68796</td></tr><tr><td>Validation Recall</td><td>0.70782</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/bivaucdb' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/bivaucdb</a><br> View project at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250818_204440-bivaucdb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-18 23:17:57,649] Trial 0 finished with value: 0.6945423274562295 and parameters: {'learning_rate': 3.3114161071670855e-05, 'weight_decay': 0.02579334100215903, 'batch_size': 64, 'num_layers': 5}. Best is trial 0 with value: 0.6945423274562295.\n",
      "/tmp/ipykernel_2912973/2845401944.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
      "/tmp/ipykernel_2912973/2845401944.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 5e-3, 3e-2)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idok/git/deep-tweet-covid/wandb/run-20250818_231759-j3r2x3hk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/j3r2x3hk' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/j3r2x3hk' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/j3r2x3hk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idok/git/deep-tweet-covid/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.6114 val_f1=0.0822, best_val_f1=0.0822\n",
      "Epoch 2: train_loss=1.4283 val_f1=0.4583, best_val_f1=0.4583\n",
      "Epoch 3: train_loss=1.0806 val_f1=0.5599, best_val_f1=0.5599\n",
      "Epoch 4: train_loss=0.9642 val_f1=0.5888, best_val_f1=0.5888\n",
      "Epoch 5: train_loss=0.9092 val_f1=0.6072, best_val_f1=0.6072\n",
      "Epoch 6: train_loss=0.8681 val_f1=0.6135, best_val_f1=0.6135\n",
      "Epoch 7: train_loss=0.8343 val_f1=0.6073, best_val_f1=0.6135\n",
      "Epoch 8: train_loss=0.8248 val_f1=0.6139, best_val_f1=0.6139\n",
      "Epoch 9: train_loss=0.7947 val_f1=0.6103, best_val_f1=0.6139\n",
      "Epoch 10: train_loss=0.7711 val_f1=0.6176, best_val_f1=0.6176\n",
      "Epoch 11: train_loss=0.7494 val_f1=0.6397, best_val_f1=0.6397\n",
      "Epoch 12: train_loss=0.7306 val_f1=0.6332, best_val_f1=0.6397\n",
      "Epoch 13: train_loss=0.7103 val_f1=0.6282, best_val_f1=0.6397\n",
      "Epoch 14: train_loss=0.6964 val_f1=0.6370, best_val_f1=0.6397\n",
      "Epoch 15: train_loss=0.6773 val_f1=0.6437, best_val_f1=0.6437\n",
      "Epoch 16: train_loss=0.6636 val_f1=0.6548, best_val_f1=0.6548\n",
      "Epoch 17: train_loss=0.6532 val_f1=0.6551, best_val_f1=0.6551\n",
      "Epoch 18: train_loss=0.6403 val_f1=0.6472, best_val_f1=0.6551\n",
      "Epoch 19: train_loss=0.6343 val_f1=0.6468, best_val_f1=0.6551\n",
      "Epoch 20: train_loss=0.6320 val_f1=0.6501, best_val_f1=0.6551\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▆▆▆▇▇▇▇▇▇████████</td></tr><tr><td>Train Loss</td><td>█▇▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Validation AUC</td><td>▁▆▇▇████████████████</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▇▇▇▇▇▇▇██████████</td></tr><tr><td>Validation F1</td><td>▁▆▇▇▇▇▇▇▇███████████</td></tr><tr><td>Validation Loss</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▅▆▇▇▇▇▇▇▇██████████</td></tr><tr><td>Validation Recall</td><td>▁▆▇▇▇███████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.72738</td></tr><tr><td>Train Loss</td><td>0.63201</td></tr><tr><td>Validation AUC</td><td>0.89774</td></tr><tr><td>Validation Accuracy</td><td>0.63808</td></tr><tr><td>Validation F1</td><td>0.65008</td></tr><tr><td>Validation Loss</td><td>0.88665</td></tr><tr><td>Validation Precision</td><td>0.6417</td></tr><tr><td>Validation Recall</td><td>0.66865</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/j3r2x3hk' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/j3r2x3hk</a><br> View project at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250818_231759-j3r2x3hk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-19 00:01:08,534] Trial 1 finished with value: 0.6551492141501705 and parameters: {'learning_rate': 2.0256774853154974e-05, 'weight_decay': 0.01808148312270186, 'batch_size': 32, 'num_layers': 3}. Best is trial 0 with value: 0.6945423274562295.\n",
      "/tmp/ipykernel_2912973/2845401944.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
      "/tmp/ipykernel_2912973/2845401944.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 5e-3, 3e-2)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idok/git/deep-tweet-covid/wandb/run-20250819_000109-frk7msqe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/frk7msqe' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/frk7msqe' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/frk7msqe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idok/git/deep-tweet-covid/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.6097 val_f1=0.1257, best_val_f1=0.1257\n",
      "Epoch 2: train_loss=1.3902 val_f1=0.4700, best_val_f1=0.4700\n",
      "Epoch 3: train_loss=1.0887 val_f1=0.5032, best_val_f1=0.5032\n",
      "Epoch 4: train_loss=1.0124 val_f1=0.5293, best_val_f1=0.5293\n",
      "Epoch 5: train_loss=0.9538 val_f1=0.5784, best_val_f1=0.5784\n",
      "Epoch 6: train_loss=0.8895 val_f1=0.5766, best_val_f1=0.5784\n",
      "Epoch 7: train_loss=0.8593 val_f1=0.6026, best_val_f1=0.6026\n",
      "Epoch 8: train_loss=0.8237 val_f1=0.6064, best_val_f1=0.6064\n",
      "Epoch 9: train_loss=0.7999 val_f1=0.6134, best_val_f1=0.6134\n",
      "Epoch 10: train_loss=0.7755 val_f1=0.6100, best_val_f1=0.6134\n",
      "Epoch 11: train_loss=0.7561 val_f1=0.6194, best_val_f1=0.6194\n",
      "Epoch 12: train_loss=0.7181 val_f1=0.6169, best_val_f1=0.6194\n",
      "Epoch 13: train_loss=0.7080 val_f1=0.6298, best_val_f1=0.6298\n",
      "Epoch 14: train_loss=0.6890 val_f1=0.6324, best_val_f1=0.6324\n",
      "Epoch 15: train_loss=0.6770 val_f1=0.6285, best_val_f1=0.6324\n",
      "Epoch 16: train_loss=0.6624 val_f1=0.6383, best_val_f1=0.6383\n",
      "Epoch 17: train_loss=0.6510 val_f1=0.6364, best_val_f1=0.6383\n",
      "Epoch 18: train_loss=0.6442 val_f1=0.6313, best_val_f1=0.6383\n",
      "Epoch 19: train_loss=0.6398 val_f1=0.6328, best_val_f1=0.6383\n",
      "Epoch 20: train_loss=0.6312 val_f1=0.6322, best_val_f1=0.6383\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▅▆▆▇▇▇▇▇▇████████</td></tr><tr><td>Train Loss</td><td>█▆▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Validation AUC</td><td>▁▆▇▇████████████████</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▆▇▇▇▇████████████</td></tr><tr><td>Validation F1</td><td>▁▆▆▇▇▇██████████████</td></tr><tr><td>Validation Loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▆▆▇▇▇▇█████████████</td></tr><tr><td>Validation Recall</td><td>▁▆▇▇▇▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.72838</td></tr><tr><td>Train Loss</td><td>0.63115</td></tr><tr><td>Validation AUC</td><td>0.88772</td></tr><tr><td>Validation Accuracy</td><td>0.62107</td></tr><tr><td>Validation F1</td><td>0.63225</td></tr><tr><td>Validation Loss</td><td>0.95047</td></tr><tr><td>Validation Precision</td><td>0.62478</td></tr><tr><td>Validation Recall</td><td>0.65521</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/frk7msqe' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/frk7msqe</a><br> View project at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250819_000109-frk7msqe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-19 00:45:32,443] Trial 2 finished with value: 0.6383401218633841 and parameters: {'learning_rate': 1.708270667144254e-05, 'weight_decay': 0.020425638527464964, 'batch_size': 16, 'num_layers': 2}. Best is trial 0 with value: 0.6945423274562295.\n",
      "/tmp/ipykernel_2912973/2845401944.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
      "/tmp/ipykernel_2912973/2845401944.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 5e-3, 3e-2)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idok/git/deep-tweet-covid/wandb/run-20250819_004533-au7huymq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/au7huymq' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/au7huymq' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/au7huymq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idok/git/deep-tweet-covid/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.6119 val_f1=0.1058, best_val_f1=0.1058\n",
      "Epoch 2: train_loss=1.3068 val_f1=0.5250, best_val_f1=0.5250\n",
      "Epoch 3: train_loss=1.0086 val_f1=0.5601, best_val_f1=0.5601\n",
      "Epoch 4: train_loss=0.9052 val_f1=0.6110, best_val_f1=0.6110\n",
      "Epoch 5: train_loss=0.8475 val_f1=0.6354, best_val_f1=0.6354\n",
      "Epoch 6: train_loss=0.8083 val_f1=0.6574, best_val_f1=0.6574\n",
      "Epoch 7: train_loss=0.7587 val_f1=0.6439, best_val_f1=0.6574\n",
      "Epoch 8: train_loss=0.7176 val_f1=0.6452, best_val_f1=0.6574\n",
      "Epoch 9: train_loss=0.6855 val_f1=0.6618, best_val_f1=0.6618\n",
      "Epoch 10: train_loss=0.6412 val_f1=0.6628, best_val_f1=0.6628\n",
      "Epoch 11: train_loss=0.6281 val_f1=0.6667, best_val_f1=0.6667\n",
      "Epoch 12: train_loss=0.5941 val_f1=0.6618, best_val_f1=0.6667\n",
      "Epoch 13: train_loss=0.5667 val_f1=0.6776, best_val_f1=0.6776\n",
      "Epoch 14: train_loss=0.5476 val_f1=0.6868, best_val_f1=0.6868\n",
      "Epoch 15: train_loss=0.5278 val_f1=0.6911, best_val_f1=0.6911\n",
      "Epoch 16: train_loss=0.5079 val_f1=0.6810, best_val_f1=0.6911\n",
      "Epoch 17: train_loss=0.4940 val_f1=0.6901, best_val_f1=0.6911\n",
      "Epoch 18: train_loss=0.4823 val_f1=0.6833, best_val_f1=0.6911\n",
      "Epoch 19: train_loss=0.4730 val_f1=0.6853, best_val_f1=0.6911\n",
      "Epoch 20: train_loss=0.4620 val_f1=0.6855, best_val_f1=0.6911\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▅▆▆▆▇▇▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▆▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation AUC</td><td>▁▆▇▇████████████████</td></tr><tr><td>Validation Accuracy</td><td>▁▆▆▇▇█▇▇████████████</td></tr><tr><td>Validation F1</td><td>▁▆▆▇▇█▇▇████████████</td></tr><tr><td>Validation Loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂</td></tr><tr><td>Validation Precision</td><td>▁▆▆▇▇█▇▇████████████</td></tr><tr><td>Validation Recall</td><td>▁▆▇▇▇███████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.80638</td></tr><tr><td>Train Loss</td><td>0.46198</td></tr><tr><td>Validation AUC</td><td>0.91069</td></tr><tr><td>Validation Accuracy</td><td>0.67355</td></tr><tr><td>Validation F1</td><td>0.68548</td></tr><tr><td>Validation Loss</td><td>0.91195</td></tr><tr><td>Validation Precision</td><td>0.67893</td></tr><tr><td>Validation Recall</td><td>0.69834</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/au7huymq' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/au7huymq</a><br> View project at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250819_004533-au7huymq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-19 01:31:52,564] Trial 3 finished with value: 0.6911161852054347 and parameters: {'learning_rate': 2.4765278693100987e-05, 'weight_decay': 0.008414435026754576, 'batch_size': 32, 'num_layers': 4}. Best is trial 0 with value: 0.6945423274562295.\n",
      "/tmp/ipykernel_2912973/2845401944.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
      "/tmp/ipykernel_2912973/2845401944.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 5e-3, 3e-2)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idok/git/deep-tweet-covid/wandb/run-20250819_013153-2utsou2k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/2utsou2k' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/2utsou2k' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/2utsou2k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idok/git/deep-tweet-covid/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.6123 val_f1=0.1752, best_val_f1=0.1752\n",
      "Epoch 2: train_loss=1.5766 val_f1=0.3418, best_val_f1=0.3418\n",
      "Epoch 3: train_loss=1.2360 val_f1=0.4675, best_val_f1=0.4675\n",
      "Epoch 4: train_loss=1.1057 val_f1=0.4808, best_val_f1=0.4808\n",
      "Epoch 5: train_loss=1.0475 val_f1=0.5025, best_val_f1=0.5025\n",
      "Epoch 6: train_loss=1.0256 val_f1=0.5375, best_val_f1=0.5375\n",
      "Epoch 7: train_loss=1.0028 val_f1=0.5324, best_val_f1=0.5375\n",
      "Epoch 8: train_loss=0.9783 val_f1=0.5506, best_val_f1=0.5506\n",
      "Epoch 9: train_loss=0.9565 val_f1=0.5639, best_val_f1=0.5639\n",
      "Epoch 10: train_loss=0.9430 val_f1=0.5741, best_val_f1=0.5741\n",
      "Epoch 11: train_loss=0.9263 val_f1=0.5744, best_val_f1=0.5744\n",
      "Epoch 12: train_loss=0.9113 val_f1=0.5730, best_val_f1=0.5744\n",
      "Epoch 13: train_loss=0.8998 val_f1=0.5818, best_val_f1=0.5818\n",
      "Epoch 14: train_loss=0.8877 val_f1=0.5820, best_val_f1=0.5820\n",
      "Epoch 15: train_loss=0.8796 val_f1=0.5892, best_val_f1=0.5892\n",
      "Epoch 16: train_loss=0.8760 val_f1=0.5894, best_val_f1=0.5894\n",
      "Epoch 17: train_loss=0.8683 val_f1=0.5895, best_val_f1=0.5895\n",
      "Epoch 18: train_loss=0.8603 val_f1=0.5859, best_val_f1=0.5895\n",
      "Epoch 19: train_loss=0.8602 val_f1=0.5899, best_val_f1=0.5899\n",
      "Epoch 20: train_loss=0.8565 val_f1=0.5892, best_val_f1=0.5899\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▂▅▆▆▇▇▇▇▇▇▇████████</td></tr><tr><td>Train Loss</td><td>██▅▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation AUC</td><td>▁▄▇▇▇▇▇█████████████</td></tr><tr><td>Validation Accuracy</td><td>▁▄▆▆▆▇▇▇████████████</td></tr><tr><td>Validation F1</td><td>▁▄▆▆▇▇▇▇████████████</td></tr><tr><td>Validation Loss</td><td>█▆▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▃▅▆▆▇▇▇▇███████████</td></tr><tr><td>Validation Recall</td><td>▁▄▆▇▇▇▇▇████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.61522</td></tr><tr><td>Train Loss</td><td>0.8565</td></tr><tr><td>Validation AUC</td><td>0.87469</td></tr><tr><td>Validation Accuracy</td><td>0.5792</td></tr><tr><td>Validation F1</td><td>0.58917</td></tr><tr><td>Validation Loss</td><td>0.92814</td></tr><tr><td>Validation Precision</td><td>0.58122</td></tr><tr><td>Validation Recall</td><td>0.62577</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/2utsou2k' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/2utsou2k</a><br> View project at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250819_013153-2utsou2k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-19 02:15:55,847] Trial 4 finished with value: 0.5898548849614988 and parameters: {'learning_rate': 1.3975849882027014e-05, 'weight_decay': 0.014060688680822551, 'batch_size': 32, 'num_layers': 2}. Best is trial 0 with value: 0.6945423274562295.\n",
      "/tmp/ipykernel_2912973/2845401944.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
      "/tmp/ipykernel_2912973/2845401944.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 5e-3, 3e-2)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idok/git/deep-tweet-covid/wandb/run-20250819_021556-qmlkvic2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/qmlkvic2' target=\"_blank\">trial_5</a></strong> to <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/qmlkvic2' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/qmlkvic2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.6114 val_f1=0.1344, best_val_f1=0.1344\n",
      "Epoch 2: train_loss=1.4630 val_f1=0.4442, best_val_f1=0.4442\n",
      "Epoch 3: train_loss=1.0976 val_f1=0.5392, best_val_f1=0.5392\n",
      "Epoch 4: train_loss=1.0118 val_f1=0.5610, best_val_f1=0.5610\n",
      "Epoch 5: train_loss=0.9595 val_f1=0.5873, best_val_f1=0.5873\n",
      "Epoch 6: train_loss=0.9092 val_f1=0.6104, best_val_f1=0.6104\n",
      "Epoch 7: train_loss=0.8507 val_f1=0.6252, best_val_f1=0.6252\n",
      "Epoch 8: train_loss=0.8298 val_f1=0.6342, best_val_f1=0.6342\n",
      "Epoch 9: train_loss=0.7979 val_f1=0.6303, best_val_f1=0.6342\n",
      "Epoch 10: train_loss=0.7632 val_f1=0.6436, best_val_f1=0.6436\n",
      "Epoch 11: train_loss=0.7373 val_f1=0.6333, best_val_f1=0.6436\n",
      "Epoch 12: train_loss=0.7102 val_f1=0.6477, best_val_f1=0.6477\n",
      "Epoch 13: train_loss=0.6862 val_f1=0.6573, best_val_f1=0.6573\n",
      "Epoch 14: train_loss=0.6729 val_f1=0.6541, best_val_f1=0.6573\n",
      "Epoch 15: train_loss=0.6527 val_f1=0.6527, best_val_f1=0.6573\n",
      "Epoch 16: train_loss=0.6361 val_f1=0.6580, best_val_f1=0.6580\n",
      "Epoch 17: train_loss=0.6254 val_f1=0.6611, best_val_f1=0.6611\n",
      "Epoch 18: train_loss=0.6115 val_f1=0.6607, best_val_f1=0.6611\n",
      "Epoch 19: train_loss=0.6043 val_f1=0.6578, best_val_f1=0.6611\n",
      "Epoch 20: train_loss=0.6015 val_f1=0.6568, best_val_f1=0.6611\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▂▅▅▆▆▆▇▇▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▇▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Validation AUC</td><td>▁▆▇▇▇███████████████</td></tr><tr><td>Validation Accuracy</td><td>▁▄▆▆▇▇▇█▇███████████</td></tr><tr><td>Validation F1</td><td>▁▅▆▇▇▇██████████████</td></tr><tr><td>Validation Loss</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▄▅▆▆▇▇▇▇█▇█████████</td></tr><tr><td>Validation Recall</td><td>▁▅▇▇▇▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.74692</td></tr><tr><td>Train Loss</td><td>0.60152</td></tr><tr><td>Validation AUC</td><td>0.89937</td></tr><tr><td>Validation Accuracy</td><td>0.64472</td></tr><tr><td>Validation F1</td><td>0.65684</td></tr><tr><td>Validation Loss</td><td>0.90583</td></tr><tr><td>Validation Precision</td><td>0.64917</td></tr><tr><td>Validation Recall</td><td>0.67542</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_5</strong> at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/qmlkvic2' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/qmlkvic2</a><br> View project at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250819_021556-qmlkvic2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-19 03:11:01,723] Trial 5 finished with value: 0.6611399643232405 and parameters: {'learning_rate': 1.0400043407839611e-05, 'weight_decay': 0.007016634072433377, 'batch_size': 16, 'num_layers': 4}. Best is trial 0 with value: 0.6945423274562295.\n",
      "/tmp/ipykernel_2912973/2845401944.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
      "/tmp/ipykernel_2912973/2845401944.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 5e-3, 3e-2)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idok/git/deep-tweet-covid/wandb/run-20250819_031102-rni6l6ax</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/rni6l6ax' target=\"_blank\">trial_6</a></strong> to <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/rni6l6ax' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/rni6l6ax</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idok/git/deep-tweet-covid/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.6108 val_f1=0.1766, best_val_f1=0.1766\n",
      "Epoch 2: train_loss=1.2040 val_f1=0.5253, best_val_f1=0.5253\n",
      "Epoch 3: train_loss=0.9736 val_f1=0.5707, best_val_f1=0.5707\n",
      "Epoch 4: train_loss=0.8973 val_f1=0.6104, best_val_f1=0.6104\n",
      "Epoch 5: train_loss=0.8452 val_f1=0.6191, best_val_f1=0.6191\n",
      "Epoch 6: train_loss=0.7942 val_f1=0.6474, best_val_f1=0.6474\n",
      "Epoch 7: train_loss=0.7516 val_f1=0.6321, best_val_f1=0.6474\n",
      "Epoch 8: train_loss=0.7224 val_f1=0.6537, best_val_f1=0.6537\n",
      "Epoch 9: train_loss=0.6617 val_f1=0.6598, best_val_f1=0.6598\n",
      "Epoch 10: train_loss=0.6356 val_f1=0.6684, best_val_f1=0.6684\n",
      "Epoch 11: train_loss=0.6099 val_f1=0.6606, best_val_f1=0.6684\n",
      "Epoch 12: train_loss=0.5584 val_f1=0.6673, best_val_f1=0.6684\n",
      "Epoch 13: train_loss=0.5445 val_f1=0.6536, best_val_f1=0.6684\n",
      "Epoch 14: train_loss=0.5199 val_f1=0.6668, best_val_f1=0.6684\n",
      "Epoch 15: train_loss=0.4939 val_f1=0.6623, best_val_f1=0.6684\n",
      "Epoch 16: train_loss=0.4704 val_f1=0.6705, best_val_f1=0.6705\n",
      "Epoch 17: train_loss=0.4533 val_f1=0.6689, best_val_f1=0.6705\n",
      "Epoch 18: train_loss=0.4403 val_f1=0.6715, best_val_f1=0.6715\n",
      "Epoch 19: train_loss=0.4272 val_f1=0.6756, best_val_f1=0.6756\n",
      "Epoch 20: train_loss=0.4168 val_f1=0.6706, best_val_f1=0.6756\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▆▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation AUC</td><td>▁▇▇▇████████████████</td></tr><tr><td>Validation Accuracy</td><td>▁▆▆▇▇█▇█████████████</td></tr><tr><td>Validation F1</td><td>▁▆▇▇▇█▇█████████████</td></tr><tr><td>Validation Loss</td><td>█▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃</td></tr><tr><td>Validation Precision</td><td>▁▅▆▇▇█▇█████████████</td></tr><tr><td>Validation Recall</td><td>▁▆▇▇▇███████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.82825</td></tr><tr><td>Train Loss</td><td>0.41675</td></tr><tr><td>Validation AUC</td><td>0.9016</td></tr><tr><td>Validation Accuracy</td><td>0.65743</td></tr><tr><td>Validation F1</td><td>0.67059</td></tr><tr><td>Validation Loss</td><td>1.03347</td></tr><tr><td>Validation Precision</td><td>0.66615</td></tr><tr><td>Validation Recall</td><td>0.68113</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_6</strong> at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/rni6l6ax' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/rni6l6ax</a><br> View project at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250819_031102-rni6l6ax/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-19 03:58:28,779] Trial 6 finished with value: 0.6756210041264392 and parameters: {'learning_rate': 2.195015337071413e-05, 'weight_decay': 0.02897319243303322, 'batch_size': 16, 'num_layers': 3}. Best is trial 0 with value: 0.6945423274562295.\n",
      "/tmp/ipykernel_2912973/2845401944.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
      "/tmp/ipykernel_2912973/2845401944.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 5e-3, 3e-2)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idok/git/deep-tweet-covid/wandb/run-20250819_035829-w07b1v5p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/w07b1v5p' target=\"_blank\">trial_7</a></strong> to <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/w07b1v5p' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/w07b1v5p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.5568 val_f1=0.4650, best_val_f1=0.4650\n",
      "Epoch 2: train_loss=1.0473 val_f1=0.5987, best_val_f1=0.5987\n",
      "Epoch 3: train_loss=0.8528 val_f1=0.6232, best_val_f1=0.6232\n",
      "Epoch 4: train_loss=0.7258 val_f1=0.6792, best_val_f1=0.6792\n",
      "Epoch 5: train_loss=0.6643 val_f1=0.6778, best_val_f1=0.6792\n",
      "Epoch 6: train_loss=0.5876 val_f1=0.7010, best_val_f1=0.7010\n",
      "Epoch 7: train_loss=0.5470 val_f1=0.6967, best_val_f1=0.7010\n",
      "Epoch 8: train_loss=0.5400 val_f1=0.6880, best_val_f1=0.7010\n",
      "Epoch 9: train_loss=0.4699 val_f1=0.6861, best_val_f1=0.7010\n",
      "Epoch 10: train_loss=0.4239 val_f1=0.7122, best_val_f1=0.7122\n",
      "Epoch 11: train_loss=0.3840 val_f1=0.7038, best_val_f1=0.7122\n",
      "Epoch 12: train_loss=0.3350 val_f1=0.7061, best_val_f1=0.7122\n",
      "Epoch 13: train_loss=0.3147 val_f1=0.7052, best_val_f1=0.7122\n",
      "Epoch 14: train_loss=0.2858 val_f1=0.7151, best_val_f1=0.7151\n",
      "Epoch 15: train_loss=0.2579 val_f1=0.7143, best_val_f1=0.7151\n",
      "Epoch 16: train_loss=0.2372 val_f1=0.7154, best_val_f1=0.7154\n",
      "Epoch 17: train_loss=0.2225 val_f1=0.7170, best_val_f1=0.7170\n",
      "Epoch 18: train_loss=0.2100 val_f1=0.7124, best_val_f1=0.7170\n",
      "Epoch 19: train_loss=0.1938 val_f1=0.7136, best_val_f1=0.7170\n",
      "Epoch 20: train_loss=0.1835 val_f1=0.7152, best_val_f1=0.7170\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▆▆▆▇▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation AUC</td><td>▁▆▆▇████████████████</td></tr><tr><td>Validation Accuracy</td><td>▁▅▅▇▇█▇▇▇███████████</td></tr><tr><td>Validation F1</td><td>▁▅▅▇▇█▇▇▇███████████</td></tr><tr><td>Validation Loss</td><td>▇▃▂▁▁▁▂▂▂▂▄▄▄▆▆▇▇███</td></tr><tr><td>Validation Precision</td><td>▁▅▆▇▇▇▇▇▇█▇█▇███████</td></tr><tr><td>Validation Recall</td><td>▁▅▆▇▇███████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.92735</td></tr><tr><td>Train Loss</td><td>0.18345</td></tr><tr><td>Validation AUC</td><td>0.91666</td></tr><tr><td>Validation Accuracy</td><td>0.70424</td></tr><tr><td>Validation F1</td><td>0.71518</td></tr><tr><td>Validation Loss</td><td>1.30548</td></tr><tr><td>Validation Precision</td><td>0.71412</td></tr><tr><td>Validation Recall</td><td>0.71704</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_7</strong> at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/w07b1v5p' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/w07b1v5p</a><br> View project at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250819_035829-w07b1v5p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-19 04:43:57,959] Trial 7 finished with value: 0.7170390352498054 and parameters: {'learning_rate': 4.9443785681517195e-05, 'weight_decay': 0.02181298694478672, 'batch_size': 32, 'num_layers': 4}. Best is trial 7 with value: 0.7170390352498054.\n",
      "/tmp/ipykernel_2912973/2845401944.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
      "/tmp/ipykernel_2912973/2845401944.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 5e-3, 3e-2)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idok/git/deep-tweet-covid/wandb/run-20250819_044358-x3imm5hh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/x3imm5hh' target=\"_blank\">trial_8</a></strong> to <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/x3imm5hh' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/x3imm5hh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idok/git/deep-tweet-covid/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.6090 val_f1=0.1483, best_val_f1=0.1483\n",
      "Epoch 2: train_loss=1.3830 val_f1=0.4661, best_val_f1=0.4661\n",
      "Epoch 3: train_loss=1.0610 val_f1=0.5381, best_val_f1=0.5381\n",
      "Epoch 4: train_loss=0.9484 val_f1=0.6106, best_val_f1=0.6106\n",
      "Epoch 5: train_loss=0.8885 val_f1=0.5967, best_val_f1=0.6106\n",
      "Epoch 6: train_loss=0.8534 val_f1=0.6094, best_val_f1=0.6106\n",
      "Epoch 7: train_loss=0.8264 val_f1=0.6219, best_val_f1=0.6219\n",
      "Epoch 8: train_loss=0.7808 val_f1=0.6168, best_val_f1=0.6219\n",
      "Epoch 9: train_loss=0.7393 val_f1=0.6539, best_val_f1=0.6539\n",
      "Epoch 10: train_loss=0.7196 val_f1=0.6471, best_val_f1=0.6539\n",
      "Epoch 11: train_loss=0.6956 val_f1=0.6528, best_val_f1=0.6539\n",
      "Epoch 12: train_loss=0.6652 val_f1=0.6715, best_val_f1=0.6715\n",
      "Epoch 13: train_loss=0.6474 val_f1=0.6677, best_val_f1=0.6715\n",
      "Epoch 14: train_loss=0.6220 val_f1=0.6570, best_val_f1=0.6715\n",
      "Epoch 15: train_loss=0.6046 val_f1=0.6662, best_val_f1=0.6715\n",
      "Epoch 16: train_loss=0.5916 val_f1=0.6754, best_val_f1=0.6754\n",
      "Epoch 17: train_loss=0.5729 val_f1=0.6724, best_val_f1=0.6754\n",
      "Epoch 18: train_loss=0.5643 val_f1=0.6711, best_val_f1=0.6754\n",
      "Epoch 19: train_loss=0.5539 val_f1=0.6761, best_val_f1=0.6761\n",
      "Epoch 20: train_loss=0.5490 val_f1=0.6757, best_val_f1=0.6761\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▅▆▆▆▇▇▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▇▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Validation AUC</td><td>▁▆▇▇▇███████████████</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▇▇▇▇▇█▇██████████</td></tr><tr><td>Validation F1</td><td>▁▅▆▇▇▇▇▇████████████</td></tr><tr><td>Validation Loss</td><td>█▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▂▄▆▆▆▆▆▇▇▇██▇██████</td></tr><tr><td>Validation Recall</td><td>▁▆▆▇▇▇█▇████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.76886</td></tr><tr><td>Train Loss</td><td>0.54898</td></tr><tr><td>Validation AUC</td><td>0.90618</td></tr><tr><td>Validation Accuracy</td><td>0.66391</td></tr><tr><td>Validation F1</td><td>0.67572</td></tr><tr><td>Validation Loss</td><td>0.88185</td></tr><tr><td>Validation Precision</td><td>0.66866</td></tr><tr><td>Validation Recall</td><td>0.69271</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_8</strong> at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/x3imm5hh' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/x3imm5hh</a><br> View project at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250819_044358-x3imm5hh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-19 05:29:24,694] Trial 8 finished with value: 0.6760542455428501 and parameters: {'learning_rate': 2.0859463095012422e-05, 'weight_decay': 0.009329856000113509, 'batch_size': 32, 'num_layers': 4}. Best is trial 7 with value: 0.7170390352498054.\n",
      "/tmp/ipykernel_2912973/2845401944.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
      "/tmp/ipykernel_2912973/2845401944.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 5e-3, 3e-2)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idok/git/deep-tweet-covid/wandb/run-20250819_052925-ay4x3lvq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/ay4x3lvq' target=\"_blank\">trial_9</a></strong> to <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/ay4x3lvq' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/ay4x3lvq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idok/git/deep-tweet-covid/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.6116 val_f1=0.0978, best_val_f1=0.0978\n",
      "Epoch 2: train_loss=1.4183 val_f1=0.4737, best_val_f1=0.4737\n",
      "Epoch 3: train_loss=1.0779 val_f1=0.5745, best_val_f1=0.5745\n",
      "Epoch 4: train_loss=0.9408 val_f1=0.5795, best_val_f1=0.5795\n",
      "Epoch 5: train_loss=0.8638 val_f1=0.6187, best_val_f1=0.6187\n",
      "Epoch 6: train_loss=0.8017 val_f1=0.6395, best_val_f1=0.6395\n",
      "Epoch 7: train_loss=0.7416 val_f1=0.6403, best_val_f1=0.6403\n",
      "Epoch 8: train_loss=0.6968 val_f1=0.6536, best_val_f1=0.6536\n",
      "Epoch 9: train_loss=0.6687 val_f1=0.6532, best_val_f1=0.6536\n",
      "Epoch 10: train_loss=0.6455 val_f1=0.6471, best_val_f1=0.6536\n",
      "Epoch 11: train_loss=0.6218 val_f1=0.6640, best_val_f1=0.6640\n",
      "Epoch 12: train_loss=0.5901 val_f1=0.6470, best_val_f1=0.6640\n",
      "Epoch 13: train_loss=0.5709 val_f1=0.6578, best_val_f1=0.6640\n",
      "Epoch 14: train_loss=0.5550 val_f1=0.6516, best_val_f1=0.6640\n",
      "Epoch 15: train_loss=0.5292 val_f1=0.6525, best_val_f1=0.6640\n",
      "Epoch 16: train_loss=0.5103 val_f1=0.6610, best_val_f1=0.6640\n",
      "Epoch 17: train_loss=0.5064 val_f1=0.6529, best_val_f1=0.6640\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▆▆▆▇▇▇▇▇██████</td></tr><tr><td>Train Loss</td><td>█▇▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation AUC</td><td>▁▆▇▇█████████████</td></tr><tr><td>Validation Accuracy</td><td>▁▅▆▇▇████████████</td></tr><tr><td>Validation F1</td><td>▁▆▇▇▇████████████</td></tr><tr><td>Validation Loss</td><td>█▄▂▂▁▁▁▁▁▁▁▂▂▂▂▂▂</td></tr><tr><td>Validation Precision</td><td>▁▅▇▇▇████████████</td></tr><tr><td>Validation Recall</td><td>▁▆▇▇█████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>17</td></tr><tr><td>Train Accuracy</td><td>0.78333</td></tr><tr><td>Train Loss</td><td>0.50637</td></tr><tr><td>Validation AUC</td><td>0.89867</td></tr><tr><td>Validation Accuracy</td><td>0.6414</td></tr><tr><td>Validation F1</td><td>0.65287</td></tr><tr><td>Validation Loss</td><td>0.96029</td></tr><tr><td>Validation Precision</td><td>0.64581</td></tr><tr><td>Validation Recall</td><td>0.67437</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_9</strong> at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/ay4x3lvq' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/ay4x3lvq</a><br> View project at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250819_052925-ay4x3lvq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-19 06:03:20,475] Trial 9 finished with value: 0.6639700382641764 and parameters: {'learning_rate': 4.376000407045076e-05, 'weight_decay': 0.012348877605247053, 'batch_size': 64, 'num_layers': 3}. Best is trial 7 with value: 0.7170390352498054.\n",
      "/tmp/ipykernel_2912973/2845401944.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
      "/tmp/ipykernel_2912973/2845401944.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 5e-3, 3e-2)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idok/git/deep-tweet-covid/wandb/run-20250819_060321-10zoxdq1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/10zoxdq1' target=\"_blank\">trial_10</a></strong> to <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/10zoxdq1' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/10zoxdq1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.5921 val_f1=0.3176, best_val_f1=0.3176\n",
      "Epoch 2: train_loss=1.0670 val_f1=0.6138, best_val_f1=0.6138\n",
      "Epoch 3: train_loss=0.8323 val_f1=0.6543, best_val_f1=0.6543\n",
      "Epoch 4: train_loss=0.7101 val_f1=0.6951, best_val_f1=0.6951\n",
      "Epoch 5: train_loss=0.6529 val_f1=0.6740, best_val_f1=0.6951\n",
      "Epoch 6: train_loss=0.5965 val_f1=0.7062, best_val_f1=0.7062\n",
      "Epoch 7: train_loss=0.5152 val_f1=0.7071, best_val_f1=0.7071\n",
      "Epoch 8: train_loss=0.4571 val_f1=0.7236, best_val_f1=0.7236\n",
      "Epoch 9: train_loss=0.3947 val_f1=0.7176, best_val_f1=0.7236\n",
      "Epoch 10: train_loss=0.3456 val_f1=0.7318, best_val_f1=0.7318\n",
      "Epoch 11: train_loss=0.2926 val_f1=0.7279, best_val_f1=0.7318\n",
      "Epoch 12: train_loss=0.2605 val_f1=0.7301, best_val_f1=0.7318\n",
      "Epoch 13: train_loss=0.2366 val_f1=0.7379, best_val_f1=0.7379\n",
      "Epoch 14: train_loss=0.2012 val_f1=0.7265, best_val_f1=0.7379\n",
      "Epoch 15: train_loss=0.1861 val_f1=0.7352, best_val_f1=0.7379\n",
      "Epoch 16: train_loss=0.1650 val_f1=0.7365, best_val_f1=0.7379\n",
      "Epoch 17: train_loss=0.1483 val_f1=0.7361, best_val_f1=0.7379\n",
      "Epoch 18: train_loss=0.1345 val_f1=0.7304, best_val_f1=0.7379\n",
      "Epoch 19: train_loss=0.1278 val_f1=0.7339, best_val_f1=0.7379\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▆▆▇▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation AUC</td><td>▁▆▇█▇██████████████</td></tr><tr><td>Validation Accuracy</td><td>▁▆▆▇▇▇▇████████████</td></tr><tr><td>Validation F1</td><td>▁▆▇▇▇▇▇████████████</td></tr><tr><td>Validation Loss</td><td>█▂▂▁▁▁▂▁▂▂▃▄▄▅▆▇▇██</td></tr><tr><td>Validation Precision</td><td>▁▆▆▇▇▇▇█▇██████████</td></tr><tr><td>Validation Recall</td><td>▁▆▇▇▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>19</td></tr><tr><td>Train Accuracy</td><td>0.95189</td></tr><tr><td>Train Loss</td><td>0.12779</td></tr><tr><td>Validation AUC</td><td>0.92745</td></tr><tr><td>Validation Accuracy</td><td>0.72425</td></tr><tr><td>Validation F1</td><td>0.73391</td></tr><tr><td>Validation Loss</td><td>1.35739</td></tr><tr><td>Validation Precision</td><td>0.73057</td></tr><tr><td>Validation Recall</td><td>0.73909</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_10</strong> at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/10zoxdq1' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/10zoxdq1</a><br> View project at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250819_060321-10zoxdq1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-19 06:49:20,011] Trial 10 finished with value: 0.7378896406857568 and parameters: {'learning_rate': 4.974146375224901e-05, 'weight_decay': 0.005145577997310733, 'batch_size': 32, 'num_layers': 5}. Best is trial 10 with value: 0.7378896406857568.\n",
      "/tmp/ipykernel_2912973/2845401944.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
      "/tmp/ipykernel_2912973/2845401944.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 5e-3, 3e-2)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idok/git/deep-tweet-covid/wandb/run-20250819_064920-or7yitqg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/or7yitqg' target=\"_blank\">trial_11</a></strong> to <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/or7yitqg' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/or7yitqg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.5555 val_f1=0.4467, best_val_f1=0.4467\n",
      "Epoch 2: train_loss=1.0125 val_f1=0.6266, best_val_f1=0.6266\n",
      "Epoch 3: train_loss=0.8020 val_f1=0.6832, best_val_f1=0.6832\n",
      "Epoch 4: train_loss=0.6708 val_f1=0.7005, best_val_f1=0.7005\n",
      "Epoch 5: train_loss=0.6022 val_f1=0.7060, best_val_f1=0.7060\n",
      "Epoch 6: train_loss=0.5238 val_f1=0.7128, best_val_f1=0.7128\n",
      "Epoch 7: train_loss=0.4787 val_f1=0.7126, best_val_f1=0.7128\n",
      "Epoch 8: train_loss=0.4497 val_f1=0.7196, best_val_f1=0.7196\n",
      "Epoch 9: train_loss=0.3881 val_f1=0.7179, best_val_f1=0.7196\n",
      "Epoch 10: train_loss=0.3628 val_f1=0.7254, best_val_f1=0.7254\n",
      "Epoch 11: train_loss=0.3156 val_f1=0.7281, best_val_f1=0.7281\n",
      "Epoch 12: train_loss=0.2614 val_f1=0.7301, best_val_f1=0.7301\n",
      "Epoch 13: train_loss=0.2128 val_f1=0.7272, best_val_f1=0.7301\n",
      "Epoch 14: train_loss=0.1966 val_f1=0.7339, best_val_f1=0.7339\n",
      "Epoch 15: train_loss=0.1769 val_f1=0.7355, best_val_f1=0.7355\n",
      "Epoch 16: train_loss=0.1554 val_f1=0.7285, best_val_f1=0.7355\n",
      "Epoch 17: train_loss=0.1449 val_f1=0.7299, best_val_f1=0.7355\n",
      "Epoch 18: train_loss=0.1348 val_f1=0.7331, best_val_f1=0.7355\n",
      "Epoch 19: train_loss=0.1229 val_f1=0.7347, best_val_f1=0.7355\n",
      "Epoch 20: train_loss=0.1150 val_f1=0.7352, best_val_f1=0.7355\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▆▆▇▇▇▇▇████████</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation AUC</td><td>▁▆▇▇▇███████████████</td></tr><tr><td>Validation Accuracy</td><td>▁▅▇▇▇▇▇█████████████</td></tr><tr><td>Validation F1</td><td>▁▅▇▇▇▇▇█████████████</td></tr><tr><td>Validation Loss</td><td>▅▂▁▁▁▁▁▂▃▃▃▄▅▅▅▆▇▇██</td></tr><tr><td>Validation Precision</td><td>▁▅▇▇▇▇▇▇████████████</td></tr><tr><td>Validation Recall</td><td>▁▅▇▇▇█▇█████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.95606</td></tr><tr><td>Train Loss</td><td>0.11496</td></tr><tr><td>Validation AUC</td><td>0.92816</td></tr><tr><td>Validation Accuracy</td><td>0.72522</td></tr><tr><td>Validation F1</td><td>0.73518</td></tr><tr><td>Validation Loss</td><td>1.44857</td></tr><tr><td>Validation Precision</td><td>0.73211</td></tr><tr><td>Validation Recall</td><td>0.73902</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_11</strong> at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/or7yitqg' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/or7yitqg</a><br> View project at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250819_064920-or7yitqg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-19 07:37:44,705] Trial 11 finished with value: 0.7355360923348476 and parameters: {'learning_rate': 4.945934716001909e-05, 'weight_decay': 0.005424771713017307, 'batch_size': 32, 'num_layers': 5}. Best is trial 10 with value: 0.7378896406857568.\n",
      "/tmp/ipykernel_2912973/2845401944.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
      "/tmp/ipykernel_2912973/2845401944.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 5e-3, 3e-2)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idok/git/deep-tweet-covid/wandb/run-20250819_073745-nj69fqje</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/nj69fqje' target=\"_blank\">trial_12</a></strong> to <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/nj69fqje' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/nj69fqje</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idok/git/deep-tweet-covid/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.6094 val_f1=0.1227, best_val_f1=0.1227\n",
      "Epoch 2: train_loss=1.1713 val_f1=0.6064, best_val_f1=0.6064\n",
      "Epoch 3: train_loss=0.8903 val_f1=0.6502, best_val_f1=0.6502\n",
      "Epoch 4: train_loss=0.7588 val_f1=0.6664, best_val_f1=0.6664\n",
      "Epoch 5: train_loss=0.6876 val_f1=0.6849, best_val_f1=0.6849\n",
      "Epoch 6: train_loss=0.6329 val_f1=0.6828, best_val_f1=0.6849\n",
      "Epoch 7: train_loss=0.5914 val_f1=0.7023, best_val_f1=0.7023\n",
      "Epoch 8: train_loss=0.5365 val_f1=0.7096, best_val_f1=0.7096\n",
      "Epoch 9: train_loss=0.4860 val_f1=0.7084, best_val_f1=0.7096\n",
      "Epoch 10: train_loss=0.4542 val_f1=0.6886, best_val_f1=0.7096\n",
      "Epoch 11: train_loss=0.4158 val_f1=0.7091, best_val_f1=0.7096\n",
      "Epoch 12: train_loss=0.3815 val_f1=0.7077, best_val_f1=0.7096\n",
      "Epoch 13: train_loss=0.3478 val_f1=0.7074, best_val_f1=0.7096\n",
      "Epoch 14: train_loss=0.3233 val_f1=0.7137, best_val_f1=0.7137\n",
      "Epoch 15: train_loss=0.2981 val_f1=0.7123, best_val_f1=0.7137\n",
      "Epoch 16: train_loss=0.2804 val_f1=0.7176, best_val_f1=0.7176\n",
      "Epoch 17: train_loss=0.2698 val_f1=0.7144, best_val_f1=0.7176\n",
      "Epoch 18: train_loss=0.2549 val_f1=0.7165, best_val_f1=0.7176\n",
      "Epoch 19: train_loss=0.2366 val_f1=0.7153, best_val_f1=0.7176\n",
      "Epoch 20: train_loss=0.2241 val_f1=0.7171, best_val_f1=0.7176\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▆▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation AUC</td><td>▁▇▇█████████████████</td></tr><tr><td>Validation Accuracy</td><td>▁▆▇▇█▇██████████████</td></tr><tr><td>Validation F1</td><td>▁▇▇▇████████████████</td></tr><tr><td>Validation Loss</td><td>█▂▁▁▁▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄</td></tr><tr><td>Validation Precision</td><td>▁▇▇▇████████████████</td></tr><tr><td>Validation Recall</td><td>▁▆▇█████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>20</td></tr><tr><td>Train Accuracy</td><td>0.90979</td></tr><tr><td>Train Loss</td><td>0.22411</td></tr><tr><td>Validation AUC</td><td>0.92236</td></tr><tr><td>Validation Accuracy</td><td>0.70667</td></tr><tr><td>Validation F1</td><td>0.71715</td></tr><tr><td>Validation Loss</td><td>1.13448</td></tr><tr><td>Validation Precision</td><td>0.71335</td></tr><tr><td>Validation Recall</td><td>0.72197</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_12</strong> at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/nj69fqje' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/nj69fqje</a><br> View project at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250819_073745-nj69fqje/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-19 08:26:07,490] Trial 12 finished with value: 0.7176063724548684 and parameters: {'learning_rate': 3.368383014427381e-05, 'weight_decay': 0.0053975720531280105, 'batch_size': 32, 'num_layers': 5}. Best is trial 10 with value: 0.7378896406857568.\n",
      "/tmp/ipykernel_2912973/2845401944.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
      "/tmp/ipykernel_2912973/2845401944.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 5e-3, 3e-2)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idok/git/deep-tweet-covid/wandb/run-20250819_082608-ukahc2g1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/ukahc2g1' target=\"_blank\">trial_13</a></strong> to <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/ukahc2g1' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/ukahc2g1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.6102 val_f1=0.1531, best_val_f1=0.1531\n",
      "Epoch 2: train_loss=1.1870 val_f1=0.5639, best_val_f1=0.5639\n",
      "Epoch 3: train_loss=0.9173 val_f1=0.6325, best_val_f1=0.6325\n",
      "Epoch 4: train_loss=0.8110 val_f1=0.6625, best_val_f1=0.6625\n",
      "Epoch 5: train_loss=0.7382 val_f1=0.6657, best_val_f1=0.6657\n",
      "Epoch 6: train_loss=0.6647 val_f1=0.6834, best_val_f1=0.6834\n",
      "Epoch 7: train_loss=0.6064 val_f1=0.6636, best_val_f1=0.6834\n",
      "Epoch 8: train_loss=0.5783 val_f1=0.6702, best_val_f1=0.6834\n",
      "Epoch 9: train_loss=0.5235 val_f1=0.7000, best_val_f1=0.7000\n",
      "Epoch 10: train_loss=0.4721 val_f1=0.6863, best_val_f1=0.7000\n",
      "Epoch 11: train_loss=0.4349 val_f1=0.6970, best_val_f1=0.7000\n",
      "Epoch 12: train_loss=0.4021 val_f1=0.7027, best_val_f1=0.7027\n",
      "Epoch 13: train_loss=0.3865 val_f1=0.7113, best_val_f1=0.7113\n",
      "Epoch 14: train_loss=0.3438 val_f1=0.7080, best_val_f1=0.7113\n",
      "Epoch 15: train_loss=0.2931 val_f1=0.7015, best_val_f1=0.7113\n",
      "Epoch 16: train_loss=0.2811 val_f1=0.7076, best_val_f1=0.7113\n",
      "Epoch 17: train_loss=0.2627 val_f1=0.7027, best_val_f1=0.7113\n",
      "Epoch 18: train_loss=0.2351 val_f1=0.7080, best_val_f1=0.7113\n",
      "Epoch 19: train_loss=0.2237 val_f1=0.7102, best_val_f1=0.7113\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Validation AUC</td><td>▁▆▇▇███████████████</td></tr><tr><td>Validation Accuracy</td><td>▁▆▇▇▇█▇▇███████████</td></tr><tr><td>Validation F1</td><td>▁▆▇▇▇█▇▇███████████</td></tr><tr><td>Validation Loss</td><td>█▃▂▁▁▁▁▂▁▂▂▂▂▃▄▃▄▄▄</td></tr><tr><td>Validation Precision</td><td>▁▅▆▇▇▇▇▇█▇█████████</td></tr><tr><td>Validation Recall</td><td>▁▆▇▇▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>19</td></tr><tr><td>Train Accuracy</td><td>0.9101</td></tr><tr><td>Train Loss</td><td>0.22365</td></tr><tr><td>Validation AUC</td><td>0.91838</td></tr><tr><td>Validation Accuracy</td><td>0.69866</td></tr><tr><td>Validation F1</td><td>0.71016</td></tr><tr><td>Validation Loss</td><td>1.17351</td></tr><tr><td>Validation Precision</td><td>0.70681</td></tr><tr><td>Validation Recall</td><td>0.71528</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_13</strong> at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/ukahc2g1' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/ukahc2g1</a><br> View project at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250819_082608-ukahc2g1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-19 09:13:01,582] Trial 13 finished with value: 0.711288999794248 and parameters: {'learning_rate': 3.75008962541288e-05, 'weight_decay': 0.005042121877492635, 'batch_size': 32, 'num_layers': 5}. Best is trial 10 with value: 0.7378896406857568.\n",
      "/tmp/ipykernel_2912973/2845401944.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
      "/tmp/ipykernel_2912973/2845401944.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 5e-3, 3e-2)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/idok/git/deep-tweet-covid/wandb/run-20250819_091302-hccv2la1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/hccv2la1' target=\"_blank\">trial_14</a></strong> to <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/hccv2la1' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/hccv2la1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idok/git/deep-tweet-covid/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.6070 val_f1=0.1938, best_val_f1=0.1938\n",
      "Epoch 2: train_loss=1.1848 val_f1=0.5972, best_val_f1=0.5972\n",
      "Epoch 3: train_loss=0.9125 val_f1=0.6139, best_val_f1=0.6139\n",
      "Epoch 4: train_loss=0.7977 val_f1=0.6488, best_val_f1=0.6488\n",
      "Epoch 5: train_loss=0.7276 val_f1=0.6818, best_val_f1=0.6818\n",
      "Epoch 6: train_loss=0.6773 val_f1=0.6842, best_val_f1=0.6842\n",
      "Epoch 7: train_loss=0.6404 val_f1=0.6968, best_val_f1=0.6968\n",
      "Epoch 8: train_loss=0.5982 val_f1=0.6924, best_val_f1=0.6968\n",
      "Epoch 9: train_loss=0.5572 val_f1=0.6936, best_val_f1=0.6968\n",
      "Epoch 10: train_loss=0.5295 val_f1=0.7075, best_val_f1=0.7075\n",
      "Epoch 11: train_loss=0.4894 val_f1=0.7015, best_val_f1=0.7075\n",
      "Epoch 12: train_loss=0.4621 val_f1=0.6915, best_val_f1=0.7075\n",
      "Epoch 13: train_loss=0.4342 val_f1=0.7026, best_val_f1=0.7075\n",
      "Epoch 14: train_loss=0.4038 val_f1=0.7024, best_val_f1=0.7075\n",
      "Epoch 15: train_loss=0.3856 val_f1=0.7039, best_val_f1=0.7075\n",
      "Epoch 16: train_loss=0.3640 val_f1=0.7059, best_val_f1=0.7075\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▆▇▇▇▇▇█████</td></tr><tr><td>Train Loss</td><td>█▆▄▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>Validation AUC</td><td>▁▇▇█████████████</td></tr><tr><td>Validation Accuracy</td><td>▁▆▇▇████████████</td></tr><tr><td>Validation F1</td><td>▁▆▇▇████████████</td></tr><tr><td>Validation Loss</td><td>█▃▂▁▁▁▁▁▁▁▁▂▂▂▂▃</td></tr><tr><td>Validation Precision</td><td>▁▇▇▇████████████</td></tr><tr><td>Validation Recall</td><td>▁▆▇▇████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>16</td></tr><tr><td>Train Accuracy</td><td>0.84932</td></tr><tr><td>Train Loss</td><td>0.36403</td></tr><tr><td>Validation AUC</td><td>0.91697</td></tr><tr><td>Validation Accuracy</td><td>0.69404</td></tr><tr><td>Validation F1</td><td>0.70586</td></tr><tr><td>Validation Loss</td><td>0.97215</td></tr><tr><td>Validation Precision</td><td>0.70063</td></tr><tr><td>Validation Recall</td><td>0.71811</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_14</strong> at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/hccv2la1' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base/runs/hccv2la1</a><br> View project at: <a href='https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base' target=\"_blank\">https://wandb.ai/yoyulia-tel-aviv-university/covid-sentiment-twitter-deberta-v3-base</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250819_091302-hccv2la1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-19 09:52:27,481] Trial 14 finished with value: 0.7075298468661098 and parameters: {'learning_rate': 2.8145246238112575e-05, 'weight_decay': 0.0065469647902776165, 'batch_size': 32, 'num_layers': 5}. Best is trial 10 with value: 0.7378896406857568.\n"
     ]
    }
   ],
   "source": [
    "# Optuna Study\n",
    "study = optuna.create_study(direction=\"maximize\")  # Specifies that the goal of the optimization is to maximize the objective function\n",
    "study.optimize(objective, n_trials=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f5006a-d8b8-4d77-9e8e-908477135903",
   "metadata": {},
   "source": [
    "# Testing - note didn't run yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b7dba8-0aaf-406b-acdd-7218e54b06c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model\n",
    "def evaluate_model(model_path, test_loader):\n",
    "    # Load the model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\", num_labels=5, ignore_mismatched_sizes=True).to(device)\n",
    "    model.load_state_dict(torch.load(model_path)) # loading the trained model\n",
    "    model = model.to(device)\n",
    "    model.eval() # eval mode\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    #same idea... just testing and getting resuts...\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    return {\"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall, \"F1 Score\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73efe752-1581-42b5-a607-e3de3e30934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data set\n",
    "test_dataset = DataLoader(test_df, AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\", use_fast=True))\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed8fef3-014e-429e-a274-b897ca3db0e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test multiple models\n",
    "model_paths = [\"best_model_trial_0.pt\"]  # Replace with actual model paths\n",
    "for model_path in model_paths:\n",
    "    metrics = evaluate_model(model_path, test_loader)\n",
    "    print(f\"Metrics for {model_path}:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
